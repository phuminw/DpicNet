{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DpicNet\n",
    "\n",
    "DpicNet a deep neural network aimed to achieve good performance on [Intel Multi-class Image Classification](https://www.kaggle.com/puneet6060/intel-image-classification). DpicNet is built by transfering learning procedure from Xception deep neural network and freezing the convolutional parts, which serves as a feature extractor. The top part of DpicNet is created by adding dense hidden layers and shaping to match the number of classes in [Intel Multi-class Image Classification](https://www.kaggle.com/puneet6060/intel-image-classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.model import DpicNet\n",
    "from model.data import load_train_data, load_test_data, load_predict_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Found 14034 images belonging to 6 classes.\nFound 3000 images belonging to 6 classes.\nModel: \"DpicNet\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nxception (Model)             (None, 5, 5, 2048)        20861480  \n_________________________________________________________________\nflatten (Flatten)            (None, 51200)             0         \n_________________________________________________________________\ndense (Dense)                (None, 256)               13107456  \n_________________________________________________________________\ndense_1 (Dense)              (None, 32)                8224      \n_________________________________________________________________\ndense_2 (Dense)              (None, 6)                 198       \n=================================================================\nTotal params: 33,977,358\nTrainable params: 13,115,878\nNon-trainable params: 20,861,480\n_________________________________________________________________\n\n"
    }
   ],
   "source": [
    "train_data = load_train_data()\n",
    "test_data = load_test_data()\n",
    "hidden1_nodes = 256\n",
    "hidden2_nodes = 32\n",
    "model = DpicNet(train_data.image_shape, train_data.num_classes, (hidden1_nodes, hidden2_nodes), (None, None))\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "WARNING:tensorflow:sample_weight modes were coerced from\n  ...\n    to  \n  ['...']\nTrain for 439 steps\nEpoch 1/10\n439/439 [==============================] - 210s 478ms/step - loss: 0.8542 - accuracy: 0.7265\nEpoch 2/10\n439/439 [==============================] - 13s 30ms/step - loss: 0.4299 - accuracy: 0.8413\nEpoch 3/10\n439/439 [==============================] - 13s 29ms/step - loss: 0.3207 - accuracy: 0.8776\nEpoch 4/10\n439/439 [==============================] - 13s 30ms/step - loss: 0.2548 - accuracy: 0.9020\nEpoch 5/10\n439/439 [==============================] - 13s 29ms/step - loss: 0.1937 - accuracy: 0.9251\nEpoch 6/10\n439/439 [==============================] - 13s 30ms/step - loss: 0.1689 - accuracy: 0.9362\nEpoch 7/10\n439/439 [==============================] - 13s 29ms/step - loss: 0.1552 - accuracy: 0.9416\nEpoch 8/10\n439/439 [==============================] - 13s 29ms/step - loss: 0.1301 - accuracy: 0.9535\nEpoch 9/10\n439/439 [==============================] - 13s 29ms/step - loss: 0.1012 - accuracy: 0.9653\nEpoch 10/10\n439/439 [==============================] - 13s 29ms/step - loss: 0.1114 - accuracy: 0.9612\n"
    }
   ],
   "source": [
    "model.fit(train_data, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "WARNING:tensorflow:sample_weight modes were coerced from\n  ...\n    to  \n  ['...']\n94/94 [==============================] - 43s 457ms/step - loss: 0.7388 - accuracy: 0.8197\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[0.7388046497994281, 0.8196667]"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "model.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "WARNING:tensorflow:From /share/pkg.7/tensorflow/2.1.0/install/lib/SCC/../python3.7-gpu/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1786: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\nInstructions for updating:\nIf using Keras pass *_constraint arguments to layers.\nINFO:tensorflow:Assets written to: ./saved_models/s3/assets\n"
    }
   ],
   "source": [
    "model.save('./saved_models/s3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(4, 'sea')"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "pred_img=load_predict_data('./data/predict/1003.jpg')\n",
    "mod1 = DpicNet.load('./saved_models/s3')\n",
    "mod1.predict(pred_img)"
   ]
  }
 ]
}