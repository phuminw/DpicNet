{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DpicNet\n",
    "\n",
    "DpicNet a deep neural network aimed to achieve good performance on [Intel Multi-class Image Classification](https://www.kaggle.com/puneet6060/intel-image-classification). DpicNet is built by transfering learning procedure from Xception deep neural network and freezing the convolutional parts, which serves as a feature extractor. The top part of DpicNet is created by adding dense hidden layers and shaping to match the number of classes in [Intel Multi-class Image Classification](https://www.kaggle.com/puneet6060/intel-image-classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.model import DpicNet\n",
    "from model.data import load_train_data, load_test_data, load_predict_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Found 14034 images belonging to 6 classes.\nFound 3000 images belonging to 6 classes.\nModel: \"DpicNet\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nxception (Model)             (None, 5, 5, 2048)        20861480  \n_________________________________________________________________\nflatten_1 (Flatten)          (None, 51200)             0         \n_________________________________________________________________\ndense_3 (Dense)              (None, 8192)              419438592 \n_________________________________________________________________\ndense_4 (Dense)              (None, 1024)              8389632   \n_________________________________________________________________\ndense_5 (Dense)              (None, 6)                 6150      \n=================================================================\nTotal params: 448,695,854\nTrainable params: 427,834,374\nNon-trainable params: 20,861,480\n_________________________________________________________________\n\n"
    }
   ],
   "source": [
    "train_data = load_train_data()\n",
    "test_data = load_test_data()\n",
    "hidden1_nodes = 8192\n",
    "hidden2_nodes = 1024\n",
    "model = DpicNet(train_data.image_shape, train_data.num_classes, (hidden1_nodes, hidden2_nodes), (None, None))\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "WARNING:tensorflow:sample_weight modes were coerced from\n  ...\n    to  \n  ['...']\nTrain for 439 steps\nEpoch 1/10\n439/439 [==============================] - 25s 56ms/step - loss: 1.7321 - accuracy: 0.7761\nEpoch 2/10\n439/439 [==============================] - 21s 48ms/step - loss: 0.3870 - accuracy: 0.8603\nEpoch 3/10\n439/439 [==============================] - 21s 48ms/step - loss: 0.2559 - accuracy: 0.9063\nEpoch 4/10\n439/439 [==============================] - 21s 48ms/step - loss: 0.1886 - accuracy: 0.9333\nEpoch 5/10\n439/439 [==============================] - 21s 48ms/step - loss: 0.1396 - accuracy: 0.9513\nEpoch 6/10\n439/439 [==============================] - 21s 47ms/step - loss: 0.1151 - accuracy: 0.9618\nEpoch 7/10\n439/439 [==============================] - 21s 47ms/step - loss: 0.0848 - accuracy: 0.9726\nEpoch 8/10\n439/439 [==============================] - 21s 48ms/step - loss: 0.0832 - accuracy: 0.9734\nEpoch 9/10\n439/439 [==============================] - 21s 47ms/step - loss: 0.0846 - accuracy: 0.9748\nEpoch 10/10\n439/439 [==============================] - 21s 47ms/step - loss: 0.0515 - accuracy: 0.9840\n"
    }
   ],
   "source": [
    "model.fit(train_data, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "WARNING:tensorflow:sample_weight modes were coerced from\n  ...\n    to  \n  ['...']\n94/94 [==============================] - 5s 57ms/step - loss: 1.8090 - accuracy: 0.8427\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[1.8089886891477285, 0.8426667]"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "model.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "WARNING:tensorflow:From /share/pkg.7/tensorflow/2.1.0/install/lib/SCC/../python3.7-gpu/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1786: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\nInstructions for updating:\nIf using Keras pass *_constraint arguments to layers.\nINFO:tensorflow:Assets written to: ./saved_models/s4/assets\n"
    }
   ],
   "source": [
    "model.save('./saved_models/s4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(4, 'sea')"
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "pred_img=load_predict_data('./data/predict/1003.jpg')\n",
    "mod1 = DpicNet.load('./saved_models/s4')\n",
    "mod1.predict(pred_img)"
   ]
  }
 ]
}